# -*- coding: utf-8 -*-
"""app.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZaPD3g-zTwW-Grczb7cciMyvlor0O23J
"""



import streamlit as st
import joblib
import nltk
from nltk.stem import PorterStemmer
from nltk.tokenize import word_tokenize

# Téléchargement des ressources NLTK nécessaires
nltk.download('punkt')

# Chargement des vectoriseurs et des modèles
vectorizer_lgrg = joblib.load('models/tfidf_vectorizer_lgrg.pkl')
model_lgrg = joblib.load('models/lgrg_model.pkl')

vectorizer_mnnb = joblib.load('models/tfidf_vectorizer_mnnb.pkl')
model_mnnb = joblib.load('models/mnnb_model.pkl')

vectorizer_svc = joblib.load('models/tfidf_vectorizer_svc.pkl')
model_svc = joblib.load('models/svc_model.pkl')

# Initialisation du stemmer
stemmer = PorterStemmer()

# Définition de la liste des vectoriseurs
vectorizers = [vectorizer_lgrg, vectorizer_svc, vectorizer_mnnb]

# Liste des modèles et des vectoriseurs associés
model_names = ['Logistic Regression', 'SVC', 'Multinomial Naive Bayes']
models = [model_lgrg, model_svc, model_mnnb]

# Fonction de stemming
def stem_text(text):
    tokens = word_tokenize(text)
    stemmed_tokens = [stemmer.stem(token) for token in tokens]
    return ' '.join(stemmed_tokens)

# Fonction de prédiction
def predict(text):
    text_stemmed = stem_text(text)
    predictions = []
    for vectorizer, model in zip(vectorizers, models):
        text_vectorized = vectorizer.transform([text_stemmed])
        prediction = model.predict(text_vectorized)[0]
        predictions.append(prediction)
    return predictions

# Interface utilisateur Streamlit
st.title('Spam Detection')
st.write("Ce projet Streamlit fournit une interface utilisateur pour la détection de spam à l'aide de modèles d'apprentissage automatique. "
         "Il permet aux utilisateurs de saisir du texte à classer comme spam ou non-spam. "
         "L'application utilise des techniques de traitement du langage naturel (NLP) telles que la tokenization et le stemming, "
         "aux côtés de modèles pré-entraînés comme la régression logistique, la machine à vecteurs de support (SVC) et le modèle bayésien naïf multinomial.")

col1, col2 = st.columns(2)
col1.image('src/not_spam.png', use_column_width=True)
col2.image('src/spam.png', use_column_width=True)

# Saisie de l'utilisateur
user_input = st.text_area('Entrez le texte à classer comme spam ou non-spam')

st.write("Voici quelques exemples si vous manquez d'imagination :)")

# Tableau des exemples
table_data = {
    'Exemples': [
        "Santa Calling! Would your little ones like a call from Santa Xmas eve? Call 09058094583 to book your time.",
        "For the most sparkling shopping breaks from 45 per person; call 0121 2025050 or visit www.shortbreaks.org.uk",
        "... Are you in the pub?",
        "hows my favourite person today? r u workin hard? couldn't sleep again last nite nearly rang u at 4.30"
    ]
}
st.table(table_data)

# Bouton pour effectuer la prédiction
if st.button('Classer'):
    if user_input:
        # Prédiction
        st.write("Prédiction:")
        predictions = predict(user_input)
        for model_name, prediction in zip(model_names, predictions):
            st.write(f"{model_name}: Prédiction: {prediction}")
    else:
        st.warning('Veuillez saisir du texte à classer.')

